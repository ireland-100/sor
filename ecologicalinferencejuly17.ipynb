{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dcd3d47-950b-45be-8514-0cba46ab5f4e",
   "metadata": {},
   "source": [
    "The idea behind this notebook was to run a variety of EI on the data that we got from er total run. In particular, we are going to be making the following tables:\n",
    "1. $2\\times 2$ ER and EI -- (H,$SOR_O$)\n",
    "2. $2\\times 2$ ER and EI -- (Brazilian, $SOR_O$)\n",
    "3. $2\\times 2$ ER and EI -- (Guyanese, $SOR_O$)\n",
    "4. $2\\times 2$ ER and EI -- (Cabo Verdean, $SOR_O$)\n",
    "5. $2\\times 2$ ER and EI -- (Belizean, $SOR_O$)\n",
    "6. $2 \\times 4$ ER and EI -- (Brazilian, $SOR_O$, $W_0$, $B_0$)\n",
    "7. $2\\times 2$ ER and EI -- (Guyanese, H)\n",
    "8. $2\\times 2$ ER and EI -- (Cabo Verdean, $B_0$)\n",
    "9. $2\\times 2$ ER and EI -- (Belizean, H)\n",
    "10. $2\\times 2$ ER and EI -- (MENAW, $SOR_O$)\n",
    "11. $2\\times 2$ ER and EI -- (MENAH, $SOR_O$)\n",
    "12. $2\\times 2$ ER and EI -- (MENAS, $SOR_O$)\n",
    "13. $2\\times 2$ ER and EI -- (MENAW, $W_0$)\n",
    "14. $2\\times 2$ ER and EI -- (MENAH, $W_0$)\n",
    "15. $2\\times 2$ ER and EI -- (MENAS, $W_0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "382cd48a-35d7-47d3-a6f5-c7eb68981909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import us\n",
    "\n",
    "from census import Census\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyei.two_by_two import TwoByTwoEI\n",
    "from pyei.goodmans_er import GoodmansER\n",
    "from pyei.goodmans_er import GoodmansERBayes\n",
    "from pyei.r_by_c import RowByColumnEI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eca562-4e09-42b5-8d46-168d0a56822f",
   "metadata": {},
   "source": [
    "Read in the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48ac221e-bdeb-4f75-a689-e039901e1565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06\n",
      "25\n",
      "26\n",
      "36\n",
      "48\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'fillna'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m     state_dfs[i] = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mecologicalcsvs/\u001b[39m\u001b[33m'\u001b[39m + state + \u001b[33m'\u001b[39m\u001b[33mecological_acs_pl.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(state_dfs)):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     state_dfs[i] = \u001b[43mstate_dfs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m(\u001b[32m0\u001b[39m, inplace = \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#the EI won't run otherwise\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'fillna'"
     ]
    }
   ],
   "source": [
    "\n",
    "states_fips = [\n",
    "    \"06\", # California\n",
    "    \"25\", # Massachusetts\n",
    "    \"26\", # Michigan\n",
    "    \"36\", # New York\n",
    "    \"48\" # Texas\n",
    "] #these are the states whose files we got in ertotalrun.ipynb\n",
    "\n",
    "state_dfs = ['0']*len(states_fips)\n",
    "\n",
    "for state in states_fips:\n",
    "    df = pd.read_csv('ecologicalcsvs/' + state + 'ecological_acs_pl.csv')\n",
    "    state_dfs[i] = pd.read_csv('ecologicalcsvs/' + state + 'ecological_acs_pl.csv')\n",
    "\n",
    "for i in range(len(state_dfs)):\n",
    "    state_dfs[i] = state_dfs[i].fillna(0, inplace = True) #the EI won't run otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "939f653c-cc6a-4174-89f2-7132a6b07ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0',       Unnamed: 0  totpop_PL  hispanic_PL  white_PL  black_PL  sor_PL  state  \\\n",
      "0              0       4641          310      4311       315     121     48   \n",
      "1              1       5782         1610      5763      2174    1539     48   \n",
      "2              2       7115         2002      7109      2924    1922     48   \n",
      "3              3       4479         1631      3935       807     835     48   \n",
      "4              4       6036         1369      5506      1620     690     48   \n",
      "...          ...        ...          ...       ...       ...     ...    ...   \n",
      "6891        6891       2567         2442      1561        10     374     48   \n",
      "6892        6892        855          731       556         0      79     48   \n",
      "6893        6893       1483         1288       788        12     199     48   \n",
      "6894        6894       1744         1581      1257        16     286     48   \n",
      "6895        6895       5588         5344      3743        61     999     48   \n",
      "\n",
      "      county   tract        GEOID  ...  sudanese_ACS_pct  syrian_ACS_pct  \\\n",
      "0          1  950100  48001950100  ...               0.0             0.0   \n",
      "1          1  950401  48001950401  ...               0.0             0.0   \n",
      "2          1  950402  48001950402  ...               0.0             0.0   \n",
      "3          1  950500  48001950500  ...               0.0             0.0   \n",
      "4          1  950600  48001950600  ...               0.0             0.0   \n",
      "...      ...     ...          ...  ...               ...             ...   \n",
      "6891     505  950402  48505950402  ...               0.0             0.0   \n",
      "6892     507  950100  48507950100  ...               0.0             0.0   \n",
      "6893     507  950200  48507950200  ...               0.0             0.0   \n",
      "6894     507  950301  48507950301  ...               0.0             0.0   \n",
      "6895     507  950302  48507950302  ...               0.0             0.0   \n",
      "\n",
      "      turkish_ACS_pct  arab_ACS_pct  arab_arab_ACS_pct  arab_other_ACS_pct  \\\n",
      "0                 0.0           0.0                0.0                 0.0   \n",
      "1                 0.0           0.0                0.0                 0.0   \n",
      "2                 0.0           0.0                0.0                 0.0   \n",
      "3                 0.0           0.0                0.0                 0.0   \n",
      "4                 0.0           0.0                0.0                 0.0   \n",
      "...               ...           ...                ...                 ...   \n",
      "6891              0.0           0.0                0.0                 0.0   \n",
      "6892              0.0           0.0                0.0                 0.0   \n",
      "6893              0.0           0.0                0.0                 0.0   \n",
      "6894              0.0           0.0                0.0                 0.0   \n",
      "6895              0.0           0.0                0.0                 0.0   \n",
      "\n",
      "      chaldean_ACS_pct  mena_world_bank_ACS_pct  mena_unhcr_ACS_pct  \\\n",
      "0                  0.0                      0.0                 0.0   \n",
      "1                  0.0                      0.0                 0.0   \n",
      "2                  0.0                      0.0                 0.0   \n",
      "3                  0.0                      0.0                 0.0   \n",
      "4                  0.0                      0.0                 0.0   \n",
      "...                ...                      ...                 ...   \n",
      "6891               0.0                      0.0                 0.0   \n",
      "6892               0.0                      0.0                 0.0   \n",
      "6893               0.0                      0.0                 0.0   \n",
      "6894               0.0                      0.0                 0.0   \n",
      "6895               0.0                      0.0                 0.0   \n",
      "\n",
      "      mena_unsd_ACS_pct  \n",
      "0                   0.0  \n",
      "1                   0.0  \n",
      "2                   0.0  \n",
      "3                   0.0  \n",
      "4                   0.0  \n",
      "...                 ...  \n",
      "6891                0.0  \n",
      "6892                0.0  \n",
      "6893                0.0  \n",
      "6894                0.0  \n",
      "6895                0.0  \n",
      "\n",
      "[6896 rows x 73 columns]]\n"
     ]
    }
   ],
   "source": [
    "print(state_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40b073ac-aaef-4984-95f6-db0f3ebdcbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_by_two(df, race, ancestry_or_ethnicity, total_col):\n",
    "    candidate_name_2by2 = race\n",
    "    demographic_group_name_2by2 = ancestry_or_ethnicity\n",
    "    precinct_names = df['tract'].astype(str)\n",
    "    group_fraction_2by2 = np.array(df[ancestry_or_ethnicity]) # Change this AND candidate name below\n",
    "    votes_fraction_2by2 = np.array(df[race]) #Change this AND group name below\n",
    "    precinct_pops = np.array(df[total_col]).astype(int)\n",
    "    ei_2by2 = TwoByTwoEI(model_name=\"king99_pareto_modification\", pareto_scale=15, pareto_shape=2)\n",
    "    ei_2by2.fit(group_fraction_2by2,\n",
    "          votes_fraction_2by2,\n",
    "          precinct_pops,\n",
    "          demographic_group_name=demographic_group_name_2by2,\n",
    "          candidate_name=candidate_name_2by2,\n",
    "          precinct_names=precinct_names, # omit this line if you don't have or don't want to use precinct names\n",
    "          chains=4\n",
    "    )\n",
    "    # Generate a simple report to summarize the results\n",
    "    print(ei_2by2.summary())\n",
    "    return ei_2by2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0139a223-85bf-475c-b190-ec4326573f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ei(ei_2by2):\n",
    "\n",
    "    fig, ax = plt.subplots(2)\n",
    "\n",
    "    ei_2by2.plot(axes=ax)\n",
    "\n",
    "    ax[0].set_xlim(-0.1,1.01)\n",
    "    ax[1].set_xlim(-0.1, 1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff25e46a-c92b-4b09-8824-d3ce98ea8ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def er(group_fraction_2by2, votes_fraction_2by2, precinct_pops):\n",
    "    goodmans_er = GoodmansER(is_weighted_regression=\"True\")\n",
    "\n",
    "    goodmans_er.fit(group_fraction_2by2,\n",
    "        votes_fraction_2by2,\n",
    "        precinct_pops, # Must include populations if weighting by population\n",
    "        demographic_group_name=demographic_group_name_2by2,\n",
    "        candidate_name=candidate_name_2by2\n",
    "    )\n",
    "    print(goodmans_er.summary())\n",
    "    goodmans_er.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb78d64-1552-414e-b937-6dccb62bce19",
   "metadata": {},
   "source": [
    "# 2x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a852f5c0-51aa-408a-bd62-28b62765bff0",
   "metadata": {},
   "source": [
    "## Tracts, California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c2f3e-4a93-4064-aaa7-459497392081",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# (H, SOR_0)\n",
    "ca_sor_hispanic = two_by_two(state_dfs[0], 'sor_PL_pct', 'hispanic_PL_pct', 'totpop_PL')\n",
    "plot_ei(ca_sor_hispanic)\n",
    "er(np.array(state_dfs[0]['hispanic_PL_pct']), np.array(state_dfs[0]['sor_PL_pct']), np.array(state_dfs[0]['totpop_PL']).astype(int))\n",
    "\n",
    "# (Brazilian, SOR_0)\n",
    "ca_sor_brazil = two_by_two(state_dfs[0], 'sor_ACS_pct', 'brazilian_ACS_pct', 'totpop_ACS')\n",
    "plot_ei(ca_sor_brazil)\n",
    "er(np.array(state_dfs[0]['brazilian_ACS_pct']), np.array(state_dfs[0]['sor_ACS_pct']), np.array(state_dfs[0]['totpop_ACS']).astype(int))\n",
    "\n",
    "# (Guyanese, SOR_0)\n",
    "pop = 'guyanese_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ca_sor_guy = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_sor_guy)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))\n",
    "\n",
    "# (Cabo Verdean, SOR_0)\n",
    "pop = 'cabo_verdean_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ca_sor_cabo = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_sor_cabo)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))\n",
    "\n",
    "# (Belizean, SOR_0)\n",
    "pop = 'belizean_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ca_sor_bel = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_sor_bel)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))\n",
    "\n",
    "# (Brazilian, H)\n",
    "pop = 'brazilian_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ca_hispanic_brazil = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_hispanic_brazil)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))\n",
    "\n",
    "# (Guyanese, H)\n",
    "pop = 'guyanese_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ca_hispanic_guy = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_hispanic_guy)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))\n",
    "\n",
    "# (Cabo Verde, B_0)\n",
    "pop = 'cabo_verdean_ACS_pct'\n",
    "race = 'black_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ca_black_cabo = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_black_cabo)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))\n",
    "\n",
    "# (Belizean, H)\n",
    "pop = 'belizean_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ca_hispanic_belize = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_hispanic_belize)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_WB, SOR_0)\n",
    "pop = 'mena_world_bank_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ca_sor_world_bank = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_sor_world_bank)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNHC, SOR_0)\n",
    "pop = 'mena_unhcr_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ca_sor_unhcr = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_sor_unhcr)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNSC, SOR_0)\n",
    "pop = 'mena_unsd_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ca_sor_unsd = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_sor_unsd)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_WB, W_0)\n",
    "pop = 'mena_world_bank_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ca_w_world_bank = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_w_world_bank)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNHC, W_0)\n",
    "pop = 'mena_unhcr_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ca_w_unhcr = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_w_unhcr)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNSC, SOR_0)\n",
    "pop = 'mena_unsd_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ca_w_unsd = two_by_two(state_dfs[0], race, pop, total_pop)\n",
    "plot_ei(ca_w_unsd)\n",
    "er(np.array(state_dfs[0][pop]), np.array(state_dfs[0][race]), np.array(state_dfs[0][total_pop]).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf7237a-069f-4869-9e25-ff728740181a",
   "metadata": {},
   "source": [
    "## Tracts, Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16160a53-972e-4374-822a-2ee3644bf630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# (H, SOR_0)\n",
    "ma_sor_hispanic = two_by_two(state_dfs[1], 'sor_PL_pct', 'hispanic_PL_pct', 'totpop_PL')\n",
    "plot_ei(ma_sor_hispanic)\n",
    "er(np.array(state_dfs[1]['hispanic_PL_pct']), np.array(state_dfs[1]['sor_PL_pct']), np.array(state_dfs[1]['totpop_PL']).astype(int))\n",
    "\n",
    "# (Brazilian, SOR_0)\n",
    "ma_sor_brazil = two_by_two(state_dfs[1], 'sor_ACS_pct', 'brazilian_ACS_pct', 'totpop_ACS')\n",
    "plot_ei(ma_sor_brazil)\n",
    "er(np.array(state_dfs[1]['brazilian_ACS_pct']), np.array(state_dfs[1]['sor_ACS_pct']), np.array(state_dfs[1]['totpop_ACS']).astype(int))\n",
    "\n",
    "# (Guyanese, SOR_0)\n",
    "pop = 'guyanese_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ma_sor_guy = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_sor_guy)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))\n",
    "\n",
    "# (Cabo Verdean, SOR_0)\n",
    "pop = 'cabo_verdean_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ma_sor_cabo = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_sor_cabo)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))\n",
    "\n",
    "# (Belizean, SOR_0)\n",
    "pop = 'belizean_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ma_sor_bel = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_sor_bel)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))\n",
    "\n",
    "# (Brazilian, H)\n",
    "pop = 'brazilian_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ma_hispanic_brazil = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_hispanic_brazil)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))\n",
    "\n",
    "# (Guyanese, H)\n",
    "pop = 'guyanese_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ma_hispanic_guy = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_hispanic_guy)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))\n",
    "\n",
    "# (Cabo Verde, B_0)\n",
    "pop = 'cabo_verdean_ACS_pct'\n",
    "race = 'black_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ma_black_cabo = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_black_cabo)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))\n",
    "\n",
    "# (Belizean, H)\n",
    "pop = 'belizean_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ma_hispanic_belize = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_hispanic_belize)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_WB, SOR_0)\n",
    "pop = 'mena_world_bank_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ma_sor_world_bank = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_sor_world_bank)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNHC, SOR_0)\n",
    "pop = 'mena_unhcr_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ma_sor_unhcr = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_sor_unhcr)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNSC, SOR_0)\n",
    "pop = 'mena_unsd_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ma_sor_unsd = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_sor_unsd)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_WB, W_0)\n",
    "pop = 'mena_world_bank_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ma_w_world_bank = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_w_world_bank)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNHC, W_0)\n",
    "pop = 'mena_unhcr_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ma_w_unhcr = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_w_unhcr)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNSC, W_0)\n",
    "pop = 'mena_unsd_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ma_w_unsd = two_by_two(state_dfs[1], race, pop, total_pop)\n",
    "plot_ei(ma_w_unsd)\n",
    "er(np.array(state_dfs[1][pop]), np.array(state_dfs[1][race]), np.array(state_dfs[1][total_pop]).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e032fbd2-4267-444f-a998-2761219e5a6d",
   "metadata": {},
   "source": [
    "## Tracts, Michigan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44787ae5-f7ae-405e-8037-9465f3dac679",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# (H, SOR_0)\n",
    "mi_sor_hispanic = two_by_two(state_dfs[2], 'sor_PL_pct', 'hispanic_PL_pct', 'totpop_PL')\n",
    "plot_ei(mi_sor_hispanic)\n",
    "er(np.array(state_dfs[2]['hispanic_PL_pct']), np.array(state_dfs[2]['sor_PL_pct']), np.array(state_dfs[2]['totpop_PL']).astype(int))\n",
    "\n",
    "# (Brazilian, SOR_0)\n",
    "mi_sor_brazil = two_by_two(state_dfs[2], 'sor_ACS_pct', 'brazilian_ACS_pct', 'totpop_ACS')\n",
    "plot_ei(mi_sor_brazil)\n",
    "er(np.array(state_dfs[2]['brazilian_ACS_pct']), np.array(state_dfs[2]['sor_ACS_pct']), np.array(state_dfs[2]['totpop_ACS']).astype(int))\n",
    "\n",
    "# (Guyanese, SOR_0)\n",
    "pop = 'guyanese_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "mi_sor_guy = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_sor_guy)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))\n",
    "\n",
    "# (Cabo Verdean, SOR_0)\n",
    "pop = 'cabo_verdean_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "mi_sor_cabo = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_sor_cabo)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))\n",
    "\n",
    "# (Belizean, SOR_0)\n",
    "pop = 'belizean_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "mi_sor_bel = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_sor_bel)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))\n",
    "\n",
    "# (Brazilian, H)\n",
    "pop = 'brazilian_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "mi_hispanic_brazil = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_hispanic_brazil)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))\n",
    "\n",
    "# (Guyanese, H)\n",
    "pop = 'guyanese_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "mi_hispanic_guy = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_hispanic_guy)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))\n",
    "\n",
    "# (Cabo Verde, B_0)\n",
    "pop = 'cabo_verdean_ACS_pct'\n",
    "race = 'black_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "mi_black_cabo = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_black_cabo)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))\n",
    "\n",
    "# (Belizean, H)\n",
    "pop = 'belizean_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "mi_hispanic_belize = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_hispanic_belize)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_WB, SOR_0)\n",
    "pop = 'mena_world_bank_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "mi_sor_world_bank = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_sor_world_bank)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNHC, SOR_0)\n",
    "pop = 'mena_unhcr_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "mi_sor_unhcr = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_sor_unhcr)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNSC, SOR_0)\n",
    "pop = 'mena_unsd_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "mi_sor_unsd = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_sor_unsd)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_WB, W_0)\n",
    "pop = 'mena_world_bank_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "mi_w_world_bank = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_w_world_bank)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNHC, W_0)\n",
    "pop = 'mena_unhcr_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "mi_w_unhcr = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_w_unhcr)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNSC, W_0)\n",
    "pop = 'mena_unsd_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "mi_w_unsd = two_by_two(state_dfs[2], race, pop, total_pop)\n",
    "plot_ei(mi_w_unsd)\n",
    "er(np.array(state_dfs[2][pop]), np.array(state_dfs[2][race]), np.array(state_dfs[2][total_pop]).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d666f8-bbb1-4b96-84bc-b697dbc6fc88",
   "metadata": {},
   "source": [
    "## Tracts, New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b402e6a-5fa6-49cf-a8ab-b5c84d1a4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# (H, SOR_0)\n",
    "ny_sor_hispanic = two_by_two(state_dfs[3], 'sor_PL_pct', 'hispanic_PL_pct', 'totpop_PL')\n",
    "plot_ei(ny_sor_hispanic)\n",
    "er(np.array(state_dfs[3]['hispanic_PL_pct']), np.array(state_dfs[3]['sor_PL_pct']), np.array(state_dfs[3]['totpop_PL']).astype(int))\n",
    "\n",
    "# (Brazilian, SOR_0)\n",
    "ny_sor_brazil = two_by_two(state_dfs[3], 'sor_ACS_pct', 'brazilian_ACS_pct', 'totpop_ACS')\n",
    "plot_ei(ny_sor_brazil)\n",
    "er(np.array(state_dfs[3]['brazilian_ACS_pct']), np.array(state_dfs[3]['sor_ACS_pct']), np.array(state_dfs[3]['totpop_ACS']).astype(int))\n",
    "\n",
    "# (Guyanese, SOR_0)\n",
    "pop = 'guyanese_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ny_sor_guy = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_sor_guy)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))\n",
    "\n",
    "# (Cabo Verdean, SOR_0)\n",
    "pop = 'cabo_verdean_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ny_sor_cabo = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_sor_cabo)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))\n",
    "\n",
    "# (Belizean, SOR_0)\n",
    "pop = 'belizean_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ny_sor_bel = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_sor_bel)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))\n",
    "\n",
    "# (Brazilian, H)\n",
    "pop = 'brazilian_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ny_hispanic_brazil = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_hispanic_brazil)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))\n",
    "\n",
    "# (Guyanese, H)\n",
    "pop = 'guyanese_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ny_hispanic_guy = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_hispanic_guy)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))\n",
    "\n",
    "# (Cabo Verde, B_0)\n",
    "pop = 'cabo_verdean_ACS_pct'\n",
    "race = 'black_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ny_black_cabo = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_black_cabo)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))\n",
    "\n",
    "# (Belizean, H)\n",
    "pop = 'belizean_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ny_hispanic_belize = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_hispanic_belize)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_WB, SOR_0)\n",
    "pop = 'mena_world_bank_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ny_sor_world_bank = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_sor_world_bank)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNHC, SOR_0)\n",
    "pop = 'mena_unhcr_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ny_sor_unhcr = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_sor_unhcr)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNSC, SOR_0)\n",
    "pop = 'mena_unsd_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "ny_sor_unsd = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_sor_unsd)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_WB, W_0)\n",
    "pop = 'mena_world_bank_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ny_w_world_bank = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_w_world_bank)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNHC, W_0)\n",
    "pop = 'mena_unhcr_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ny_w_unhcr = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_w_unhcr)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNSC, W_0)\n",
    "pop = 'mena_unsd_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "ny_w_unsd = two_by_two(state_dfs[3], race, pop, total_pop)\n",
    "plot_ei(ny_w_unsd)\n",
    "er(np.array(state_dfs[3][pop]), np.array(state_dfs[3][race]), np.array(state_dfs[3][total_pop]).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5615b6a-361a-4b77-87a7-6eb2875912ae",
   "metadata": {},
   "source": [
    "## Tracts, Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20582f5-b387-400e-aab4-a2623f7b5737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# (H, SOR_0)\n",
    "tx_sor_hispanic = two_by_two(state_dfs[4], 'sor_PL_pct', 'hispanic_PL_pct', 'totpop_PL')\n",
    "plot_ei(tx_sor_hispanic)\n",
    "er(np.array(state_dfs[4]['hispanic_PL_pct']), np.array(state_dfs[4]['sor_PL_pct']), np.array(state_dfs[4]['totpop_PL']).astype(int))\n",
    "\n",
    "# (Brazilian, SOR_0)\n",
    "tx_sor_brazil = two_by_two(state_dfs[4], 'sor_ACS_pct', 'brazilian_ACS_pct', 'totpop_ACS')\n",
    "plot_ei(tx_sor_brazil)\n",
    "er(np.array(state_dfs[4]['brazilian_ACS_pct']), np.array(state_dfs[4]['sor_ACS_pct']), np.array(state_dfs[4]['totpop_ACS']).astype(int))\n",
    "\n",
    "# (Guyanese, SOR_0)\n",
    "pop = 'guyanese_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "tx_sor_guy = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_sor_guy)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))\n",
    "\n",
    "# (Cabo Verdean, SOR_0)\n",
    "pop = 'cabo_verdean_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "tx_sor_cabo = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_sor_cabo)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))\n",
    "\n",
    "# (Belizean, SOR_0)\n",
    "pop = 'belizean_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "tx_sor_bel = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_sor_bel)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))\n",
    "\n",
    "# (Brazilian, H)\n",
    "pop = 'brazilian_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "tx_hispanic_brazil = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_hispanic_brazil)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))\n",
    "\n",
    "# (Guyanese, H)\n",
    "pop = 'guyanese_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "tx_hispanic_guy = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_hispanic_guy)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))\n",
    "\n",
    "# (Cabo Verde, B_0)\n",
    "pop = 'cabo_verdean_ACS_pct'\n",
    "race = 'black_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "tx_black_cabo = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_black_cabo)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))\n",
    "\n",
    "# (Belizean, H)\n",
    "pop = 'belizean_ACS_pct'\n",
    "race = 'hispanic_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "tx_hispanic_belize = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_hispanic_belize)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_WB, SOR_0)\n",
    "pop = 'mena_world_bank_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "tx_sor_world_bank = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_sor_world_bank)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNHC, SOR_0)\n",
    "pop = 'mena_unhcr_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "tx_sor_unhcr = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_sor_unhcr)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNSC, SOR_0)\n",
    "pop = 'mena_unsd_ACS_pct'\n",
    "race = 'sor_ACS_pct'\n",
    "total_pop = 'totpop_ACS'\n",
    "tx_sor_unsd = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_sor_unsd)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_WB, W_0)\n",
    "pop = 'mena_world_bank_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "tx_w_world_bank = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_w_world_bank)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNHC, W_0)\n",
    "pop = 'mena_unhcr_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "tx_w_unhcr = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_w_unhcr)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))\n",
    "\n",
    "# (Mena_UNSC, W_0)\n",
    "pop = 'mena_unsd_ACS_pct'\n",
    "race = 'white_PL_pct'\n",
    "total_pop = 'totpop_PL'\n",
    "tx_w_unsd = two_by_two(state_dfs[4], race, pop, total_pop)\n",
    "plot_ei(tx_w_unsd)\n",
    "er(np.array(state_dfs[4][pop]), np.array(state_dfs[4][race]), np.array(state_dfs[4][total_pop]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65878c3-53e4-40d7-92ea-fb7d7e4d67db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e9c1c-7668-4c2b-88a1-a95bd03989e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433c3286-a893-4bad-b92a-1afd55146bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da42022-dd24-43d2-bc73-5f69c2650ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef387372-e9a6-444d-bd02-d16e5f6853d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d38c059-3335-4eb1-9312-0d429171e7d5",
   "metadata": {},
   "source": [
    "## Chloe's Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ce88f80a-3396-4f76-9b60-5efe6aefcaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(state_dfs[0][\"hispanic_PL_pct\"].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "09d10617-f072-4098-aa71-f1ced8654870",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dfs[0].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04d7f5b1-129f-4e3f-bbd4-92c756a5448c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ireland/anaconda3/lib/python3.11/site-packages/pyei/two_by_two.py:812: UserWarning: Precinct names are not unique. This may interfere with passing precinct names to precinct_level_plot().\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65076ee875a14f8f87157a3ceb833ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e05c929cd6410ca412f098a73b0dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b78a6296144ee9bcd63a1d283669a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d39ccc484e541a0b213a2b898cf2b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m precinct_pops = np.array(state_dfs[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotpop_PL\u001b[39m\u001b[33m\"\u001b[39m]).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      7\u001b[39m ei_2by2 = TwoByTwoEI(model_name=\u001b[33m\"\u001b[39m\u001b[33mking99_pareto_modification\u001b[39m\u001b[33m\"\u001b[39m, pareto_scale=\u001b[32m15\u001b[39m, pareto_shape=\u001b[32m2\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mei_2by2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_fraction_2by2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m      \u001b[49m\u001b[43mvotes_fraction_2by2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m      \u001b[49m\u001b[43mprecinct_pops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m      \u001b[49m\u001b[43mdemographic_group_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdemographic_group_name_2by2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcandidate_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcandidate_name_2by2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m      \u001b[49m\u001b[43mprecinct_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecinct_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# omit this line if you don't have or don't want to use precinct names\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m      \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Generate a simple report to summarize the results\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(ei_2by2.summary())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/site-packages/pyei/two_by_two.py:849\u001b[39m, in \u001b[36mTwoByTwoEI.fit\u001b[39m\u001b[34m(self, group_fraction, votes_fraction, precinct_pops, demographic_group_name, candidate_name, precinct_names, target_accept, tune, draw_samples, **other_sampling_args)\u001b[39m\n\u001b[32m    843\u001b[39m         \u001b[38;5;28mself\u001b[39m.sim_trace = pm.sample(\n\u001b[32m    844\u001b[39m             target_accept=target_accept,\n\u001b[32m    845\u001b[39m             tune=tune,\n\u001b[32m    846\u001b[39m             **other_sampling_args,\n\u001b[32m    847\u001b[39m         )\n\u001b[32m    848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m849\u001b[39m         \u001b[38;5;28mself\u001b[39m.sim_trace = \u001b[43mpm\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnuts_sampler\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnumpyro\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mother_sampling_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[38;5;28mself\u001b[39m.calculate_sampled_voting_prefs()\n\u001b[32m    857\u001b[39m \u001b[38;5;28msuper\u001b[39m().calculate_summary()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/site-packages/pymc/sampling/mcmc.py:802\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, compile_kwargs, **kwargs)\u001b[39m\n\u001b[32m    797\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    798\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mModel can not be sampled with NUTS alone. It either has discrete variables or a non-differentiable log-probability.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    799\u001b[39m         )\n\u001b[32m    801\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m joined_blas_limiter():\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_external_nuts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m            \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnuts_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnuts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtarget_accept\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m            \u001b[49m\u001b[43minitvals\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitvals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    811\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvar_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvar_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m            \u001b[49m\u001b[43midata_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43midata_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    814\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    815\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnuts_sampler_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnuts_sampler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exclusive_nuts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m provided_steps:\n\u001b[32m    820\u001b[39m     \u001b[38;5;66;03m# Special path for NUTS initialization\u001b[39;00m\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnuts\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/site-packages/pymc/sampling/mcmc.py:391\u001b[39m, in \u001b[36m_sample_external_nuts\u001b[39m\u001b[34m(sampler, draws, tune, chains, target_accept, random_seed, initvals, model, var_names, progressbar, idata_kwargs, compute_convergence_checks, nuts_sampler_kwargs, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m sampler \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mnumpyro\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mblackjax\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpymc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msampling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjax\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpymc_jax\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     idata = \u001b[43mpymc_jax\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_jax_nuts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[43minitvals\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitvals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvar_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvar_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnuts_sampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43midata_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43midata_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnuts_sampler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m idata\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/site-packages/pymc/sampling/jax.py:652\u001b[39m, in \u001b[36msample_jax_nuts\u001b[39m\u001b[34m(draws, tune, chains, target_accept, random_seed, initvals, jitter, model, var_names, nuts_kwargs, progressbar, keep_untransformed, chain_method, postprocessing_backend, postprocessing_vectorize, postprocessing_chunks, idata_kwargs, compute_convergence_checks, nuts_sampler)\u001b[39m\n\u001b[32m    642\u001b[39m initial_points = _get_batched_jittered_initial_points(\n\u001b[32m    643\u001b[39m     model=model,\n\u001b[32m    644\u001b[39m     chains=chains,\n\u001b[32m   (...)\u001b[39m\u001b[32m    648\u001b[39m     logp_fn=logp_fn,\n\u001b[32m    649\u001b[39m )\n\u001b[32m    651\u001b[39m tic1 = datetime.now()\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m raw_mcmc_samples, sample_stats, library = \u001b[43msampler_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchain_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchain_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_points\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnuts_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnuts_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogp_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogp_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m tic2 = datetime.now()\n\u001b[32m    667\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idata_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/site-packages/pymc/sampling/jax.py:503\u001b[39m, in \u001b[36m_sample_numpyro_nuts\u001b[39m\u001b[34m(model, target_accept, tune, draws, chains, chain_method, progressbar, random_seed, initial_points, nuts_kwargs, logp_fn)\u001b[39m\n\u001b[32m    489\u001b[39m pmap_numpyro.run(\n\u001b[32m    490\u001b[39m     map_seed,\n\u001b[32m    491\u001b[39m     init_params=initial_points,\n\u001b[32m   (...)\u001b[39m\u001b[32m    499\u001b[39m     ),\n\u001b[32m    500\u001b[39m )\n\u001b[32m    502\u001b[39m raw_mcmc_samples = pmap_numpyro.get_samples(group_by_chain=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m sample_stats = \u001b[43m_numpyro_stats_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpmap_numpyro\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m raw_mcmc_samples, sample_stats, numpyro\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/site-packages/pymc/sampling/jax.py:402\u001b[39m, in \u001b[36m_numpyro_stats_to_dict\u001b[39m\u001b[34m(posterior)\u001b[39m\n\u001b[32m    400\u001b[39m     data[name] = value\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stat == \u001b[33m\"\u001b[39m\u001b[33mnum_steps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m         data[\u001b[33m\"\u001b[39m\u001b[33mtree_depth\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m.astype(\u001b[38;5;28mint\u001b[39m) + \u001b[32m1\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/site-packages/jax/_src/array.py:441\u001b[39m, in \u001b[36mArrayImpl.__array__\u001b[39m\u001b[34m(self, dtype, context, copy)\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, context=\u001b[38;5;28;01mNone\u001b[39;00m, copy=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    439\u001b[39m   \u001b[38;5;66;03m# copy argument is supported by np.asarray starting in numpy 2.0\u001b[39;00m\n\u001b[32m    440\u001b[39m   kwds = {} \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[33m'\u001b[39m\u001b[33mcopy\u001b[39m\u001b[33m'\u001b[39m: copy}\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m np.asarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_value\u001b[49m, dtype=dtype, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/site-packages/jax/_src/profiler.py:354\u001b[39m, in \u001b[36mannotate_function.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    353\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, **decorator_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/site-packages/jax/_src/array.py:667\u001b[39m, in \u001b[36mArrayImpl._value\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    665\u001b[39m npy_value = np.empty(\u001b[38;5;28mself\u001b[39m.shape, \u001b[38;5;28mself\u001b[39m.dtype)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, ind \u001b[38;5;129;01min\u001b[39;00m _cached_index_calc(\u001b[38;5;28mself\u001b[39m.sharding, \u001b[38;5;28mself\u001b[39m.shape):\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m   npy_value[ind], _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_arrays\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_single_device_array_to_np_array_did_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[38;5;28mself\u001b[39m._npy_value = npy_value\n\u001b[32m    669\u001b[39m \u001b[38;5;28mself\u001b[39m._npy_value.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "candidate_name_2by2 = \"SORO\"\n",
    "demographic_group_name_2by2 = \"Hispanic\"\n",
    "precinct_names = state_dfs[0]['tract'].astype(str)\n",
    "group_fraction_2by2 = np.array(state_dfs[0][\"hispanic_PL_pct\"]) # Change this AND candidate name below\n",
    "votes_fraction_2by2 = np.array(state_dfs[0][\"sor_PL_pct\"]) #Change this AND group name below\n",
    "precinct_pops = np.array(state_dfs[0][\"totpop_PL\"]).astype(int)\n",
    "ei_2by2 = TwoByTwoEI(model_name=\"king99_pareto_modification\", pareto_scale=15, pareto_shape=2)\n",
    "ei_2by2.fit(group_fraction_2by2,\n",
    "      votes_fraction_2by2,\n",
    "      precinct_pops,\n",
    "      demographic_group_name=demographic_group_name_2by2,\n",
    "      candidate_name=candidate_name_2by2,\n",
    "      precinct_names=precinct_names, # omit this line if you don't have or don't want to use precinct names\n",
    "      chains=4\n",
    ")\n",
    "# Generate a simple report to summarize the results\n",
    "print(ei_2by2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0b3cc363-f7e8-4296-a857-698d5fb67ed6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to NoneType.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mei_2by2\u001b[49m\u001b[43m.\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/site-packages/pyei/two_by_two.py:601\u001b[39m, in \u001b[36mTwoByTwoEIBaseBayes.summary\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    599\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a summary string\"\"\"\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# TODO: probably format this as a table\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m601\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model_name\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    602\u001b[39m \u001b[33mComputed from the raw b_i samples by multiplying by population and then getting\u001b[39m\n\u001b[32m    603\u001b[39m \u001b[33mthe proportion of the total pop (total pop=summed across all districts):\u001b[39m\n\u001b[32m    604\u001b[39m \u001b[33mThe posterior mean for the district-level voting preference of\u001b[39m\n\u001b[32m    605\u001b[39m \u001b[33m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.demographic_group_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.candidate_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is\u001b[39m\n\u001b[32m    606\u001b[39m \u001b[33m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.posterior_mean_voting_prefs[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    607\u001b[39m \u001b[33mThe posterior mean for the district-level voting preference of\u001b[39m\n\u001b[32m    608\u001b[39m \u001b[33mnon-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.demographic_group_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.candidate_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[33m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.posterior_mean_voting_prefs[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    610\u001b[39m \u001b[33m95% equal-tailed Bayesian credible interval for district-level voting preference of\u001b[39m\n\u001b[32m    611\u001b[39m \u001b[33m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.demographic_group_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.candidate_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[33m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.credible_interval_95_mean_voting_prefs[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[33m95% equal-tailed Bayesian credible interval for district-level voting preference of\u001b[39m\n\u001b[32m    614\u001b[39m \u001b[33mnon-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.demographic_group_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.candidate_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[33m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.credible_interval_95_mean_voting_prefs[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    616\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported format string passed to NoneType.__format__"
     ]
    }
   ],
   "source": [
    "print(ei_2by2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f256595-9658-496f-95e3-97102b518b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02633311, 0.02048976, 0.03470203, ..., 0.03735705, 0.02698463,\n",
       "       0.00796813])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b1996-592a-43f4-b23f-d23f7e4d1fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_name_2by2 = \"SOR0\"\n",
    "demographic_group_name_2by2 = \"Hispanic\"\n",
    "precinct_names = e_df['counties']\n",
    "group_fraction_2by2 = np.array(e_df[\"h_pct\"]) # Change this AND candidate name below\n",
    "votes_fraction_2by2 = np.array(e_df[\"sor_pct\"]) #Change this AND group name below\n",
    "precinct_pops = np.array(e_df[\"total\"]).astype(int)\n",
    "ei_2by2 = TwoByTwoEI(model_name=\"king99_pareto_modification\", pareto_scale=15, pareto_shape=2)\n",
    "ei_2by2.fit(group_fraction_2by2,\n",
    "      votes_fraction_2by2,\n",
    "      precinct_pops,\n",
    "      demographic_group_name=demographic_group_name_2by2,\n",
    "      candidate_name=candidate_name_2by2,\n",
    "      precinct_names=precinct_names, # omit this line if you don't have or don't want to use precinct names\n",
    "      chains=4\n",
    ")\n",
    "# Generate a simple report to summarize the results\n",
    "print(ei_2by2.summary())\n",
    "\n",
    "goodmans_er = GoodmansER(is_weighted_regression=\"True\")\n",
    "\n",
    "goodmans_er.fit(group_fraction_2by2,\n",
    "    votes_fraction_2by2,\n",
    "    precinct_pops, # Must include populations if weighting by population\n",
    "    demographic_group_name=demographic_group_name_2by2,\n",
    "    candidate_name=candidate_name_2by2\n",
    ")\n",
    "\n",
    "print(goodmans_er.summary())\n",
    "goodmans_er.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
